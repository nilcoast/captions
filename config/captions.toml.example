[audio]
sample_rate = 16000
channels = 1
# Ring buffer duration in seconds
buffer_seconds = 30
# "sink" = system audio (speakers), "mic" = microphone
source = "sink"

[whisper]
# Path to whisper.cpp GGML model file
model_path = "~/.local/share/captions/ggml-base.en.bin"
# Chunk duration in milliseconds (how often to run inference)
chunk_ms = 3000
# Overlap in milliseconds (for context continuity)
overlap_ms = 500
# "greedy" or "beam"
strategy = "greedy"
# Number of threads for whisper inference
threads = 4
# Language code (e.g. "en", "auto")
language = "en"

[overlay]
# Font description (Pango format)
font = "Sans Bold 18"
# Text color (CSS format)
text_color = "rgba(255, 255, 255, 0.95)"
# Background color of the caption box
bg_color = "rgba(0, 0, 0, 0.70)"
# Maximum number of visible lines
max_lines = 3
# Margin from screen bottom in pixels
margin_bottom = 60
# Margin from screen sides in pixels
margin_side = 80
# Fade timeout in seconds (0 = no fade)
fade_timeout = 5
# Border radius in pixels
border_radius = 16
# Padding in pixels
padding = 16

[recording]
# Base directory for saved sessions
output_dir = "~/captions"
# Save audio as WAV
save_audio = true
# Save transcript text
save_transcript = true

[summary]
# Enable AI summary generation after session ends (uses `llm` CLI tool)
enabled = true
# Model name passed to `llm -m` (empty = llm default)
model = ""
# Prompt prepended to transcript
prompt = "Summarize the following transcript concisely, highlighting key points and action items:"

[daemon]
socket_path = "/tmp/captions.sock"
